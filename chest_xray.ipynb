{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "S4_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6WB-nA7vSGM"
      },
      "source": [
        "# 흉부X선 사진을 통한 병변 탐지\n",
        "- 방사선 노출은 암 발생 위험을 높인다.\n",
        "- X선은 CT의 2~3% 정도로 방사선량이 적다.\n",
        "- 방사선량이 적은 X선 사진을 통해 병변 탐지를 극대화 하고자한다.\n",
        "## 가설\n",
        "- 세상에는 상대적으로 많은 양의 정상 데이터와 적은 양의 비정상 데이터가 존재할 것이다.\n",
        "- autoencoder를 통해 비정상 데이터를 생성할 수 있을 것이다.\n",
        "- autoencoder GAN을 이용해 abnomaly detection을 해낼 수 있을 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sIK00OneQpO"
      },
      "source": [
        "# TensorFlow 및 기타 라이브러리 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVJDIC2-aDjO"
      },
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "random.seed(10)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6Re6P9omE3L"
      },
      "source": [
        "# 데이터세트 다운로드 및 탐색하기\n",
        "흉부x선 사진 데이터세트 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNtGGuhWmZ5s",
        "outputId": "de8a8694-08f2-479c-f28b-93c390dbd20a"
      },
      "source": [
        "import pathlib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "data_dir_train = \"gdrive/MyDrive/chest_xray/train\"\n",
        "data_dir_train = pathlib.Path(data_dir_train)\n",
        "data_dir_val = \"gdrive/MyDrive/chest_xray/val\"\n",
        "data_dir_val = pathlib.Path(data_dir_val)\n",
        "data_dir_test = \"gdrive/MyDrive/chest_xray/test\"\n",
        "data_dir_test = pathlib.Path(data_dir_test)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fb2Hjyref9c"
      },
      "source": [
        "# 데이터세트 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D71YVKDDeikq"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TnHvCxZf_Pe",
        "outputId": "55df193d-3cb7-4035-f315-3d4351d89078"
      },
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_train,\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5216 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vGmtHbDjvs8",
        "outputId": "29f94bf4-6876-40d2-9f43-f8d64b23ed48"
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_val,\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N18GatZBsHPl",
        "outputId": "14f6bd03-bc46-415e-e366-cb0d059301fa"
      },
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_test,\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 624 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKAf-btlkB17",
        "outputId": "613186c5-09fc-43f1-fd18-f04c0ff9b623"
      },
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NORMAL', 'PNEUMONIA']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIKA5DyQaDdD"
      },
      "source": [
        "# 모델 만들기\n",
        "- 데이터 증강\n",
        "- 3개 컨볼루션 블록\n",
        "- Fully connected layer\n",
        "- 드롭아웃"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDV3sWPFU3b-"
      },
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "     layers.experimental.preprocessing.RandomFlip('horizontal',\n",
        "                                                  input_shape=(img_height,\n",
        "                                                               img_width,\n",
        "                                                               3)),\n",
        "     layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "     layers.experimental.preprocessing.RandomZoom(0.1)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP1rpB0oXjT4"
      },
      "source": [
        "model = Sequential([\n",
        "                    data_augmentation,\n",
        "                    layers.experimental.preprocessing.Rescaling(1./255),\n",
        "                    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "                    layers.MaxPooling2D(),\n",
        "                    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "                    layers.MaxPooling2D(),\n",
        "                    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "                    layers.MaxPooling2D(),\n",
        "                    layers.Dropout(0.2),\n",
        "                    layers.Flatten(),\n",
        "                    layers.Dense(128, activation='relu'),\n",
        "                    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz8CyfriapfK"
      },
      "source": [
        "# 모델 컴파일하기\n",
        "- optimizers.Adam 옵티마이저\n",
        "- losses.BinaryCrossentropy 손실 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-9I007FcgPp"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is2e8J3Rd-xK"
      },
      "source": [
        "# 모델 요약"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsRUMgrJeK_K",
        "outputId": "68361054-fe69-472a-857a-2e2937d0045d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_13 (Sequential)   (None, 180, 180, 3)       0         \n",
            "_________________________________________________________________\n",
            "rescaling_8 (Rescaling)      (None, 180, 180, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 180, 180, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 90, 90, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 90, 90, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 45, 45, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 45, 45, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 30976)             0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               3965056   \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 3,988,769\n",
            "Trainable params: 3,988,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dm5ijC8fSFK"
      },
      "source": [
        "# 모델 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9P1xpUdfUlt",
        "outputId": "5a1240e4-78a1-4ed0-c9d3-c5b09d99acc7"
      },
      "source": [
        "epochs=15\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3),\n",
        "checkpoint_filepath = 'gdrive/MyDrive/chest_xray/tmp/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=[callback, model_checkpoint_callback]\n",
        ")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:5017: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`binary_crossentropy` received `from_logits=True`, but the `output`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "163/163 [==============================] - 26s 150ms/step - loss: 0.4543 - accuracy: 0.7974 - val_loss: 0.5244 - val_accuracy: 0.8750\n",
            "Epoch 2/15\n",
            "163/163 [==============================] - 25s 150ms/step - loss: 0.2594 - accuracy: 0.8913 - val_loss: 0.4597 - val_accuracy: 0.8750\n",
            "Epoch 3/15\n",
            "163/163 [==============================] - 24s 148ms/step - loss: 0.1873 - accuracy: 0.9231 - val_loss: 0.4967 - val_accuracy: 0.8125\n",
            "Epoch 4/15\n",
            "163/163 [==============================] - 25s 150ms/step - loss: 0.1758 - accuracy: 0.9312 - val_loss: 0.5436 - val_accuracy: 0.8125\n",
            "Epoch 5/15\n",
            "163/163 [==============================] - 25s 153ms/step - loss: 0.1509 - accuracy: 0.9406 - val_loss: 0.6147 - val_accuracy: 0.8125\n",
            "Epoch 6/15\n",
            "163/163 [==============================] - 25s 153ms/step - loss: 0.1392 - accuracy: 0.9471 - val_loss: 0.6266 - val_accuracy: 0.7500\n",
            "Epoch 7/15\n",
            "163/163 [==============================] - 25s 150ms/step - loss: 0.1292 - accuracy: 0.9509 - val_loss: 0.3691 - val_accuracy: 0.8750\n",
            "Epoch 8/15\n",
            "163/163 [==============================] - 24s 148ms/step - loss: 0.1246 - accuracy: 0.9523 - val_loss: 0.2845 - val_accuracy: 0.8750\n",
            "Epoch 9/15\n",
            "163/163 [==============================] - 25s 151ms/step - loss: 0.1267 - accuracy: 0.9557 - val_loss: 0.5266 - val_accuracy: 0.8125\n",
            "Epoch 10/15\n",
            "163/163 [==============================] - 24s 149ms/step - loss: 0.1170 - accuracy: 0.9530 - val_loss: 0.5121 - val_accuracy: 0.6875\n",
            "Epoch 11/15\n",
            "163/163 [==============================] - 24s 147ms/step - loss: 0.1236 - accuracy: 0.9544 - val_loss: 0.9845 - val_accuracy: 0.5625\n",
            "Epoch 12/15\n",
            "163/163 [==============================] - 24s 146ms/step - loss: 0.1044 - accuracy: 0.9632 - val_loss: 0.8146 - val_accuracy: 0.6250\n",
            "Epoch 13/15\n",
            "163/163 [==============================] - 24s 146ms/step - loss: 0.1062 - accuracy: 0.9603 - val_loss: 0.8506 - val_accuracy: 0.5000\n",
            "Epoch 14/15\n",
            "163/163 [==============================] - 25s 150ms/step - loss: 0.0986 - accuracy: 0.9632 - val_loss: 0.9717 - val_accuracy: 0.6250\n",
            "Epoch 15/15\n",
            "163/163 [==============================] - 25s 150ms/step - loss: 0.1077 - accuracy: 0.9618 - val_loss: 0.7326 - val_accuracy: 0.6875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Oic5oXZXAMy"
      },
      "source": [
        "# 예측하기\n",
        "- 이미지 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P-PCLC1W_xm",
        "outputId": "65001bde-ca67-4357-8623-b6e42f80faae"
      },
      "source": [
        "model.load_weights(checkpoint_filepath)\n",
        "\n",
        "predictions = model.predict(test_ds)\n",
        "score = tf.nn.sigmoid(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\".format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This image most likely belongs to NORMAL with a 52.77 percent confidence.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atxczkdWjJdZ"
      },
      "source": [
        "# Future work\n",
        "- autoencoder를 통한 abnomal image 생성\n",
        "- autoencoder GAN을 이용한 abnomaly detection"
      ]
    }
  ]
}